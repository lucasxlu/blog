<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>[cv] image quality assessment | LucasX</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="Machine LearningDeep LearningComputer VisionDigital Image Processing" />
  
  
  
  
  <meta name="description" content="IntroductionImage Quality Assessment (IQA) 是计算机视觉领域一个非常重要的研究方向，并且在许多方向也有着非常好的落地场景(例如在滴滴出行，就需要设计算法来实现对网约车司机上传的证件照进行图像质量分析，若存在大规模的反光(reflection)、模糊(blur)等，就需要予以拒绝)；此外，IQA也常常被用于Face Anti-Spoofing，因为有时候pr">
<meta name="keywords" content="Machine Learning,Deep Learning,Computer Vision,Digital Image Processing">
<meta property="og:type" content="article">
<meta property="og:title" content="[CV] Image Quality Assessment">
<meta property="og:url" content="https://lucasxlu.github.io/blog/2019/12/07/cv-iqa/index.html">
<meta property="og:site_name" content="LucasX">
<meta property="og:description" content="IntroductionImage Quality Assessment (IQA) 是计算机视觉领域一个非常重要的研究方向，并且在许多方向也有着非常好的落地场景(例如在滴滴出行，就需要设计算法来实现对网约车司机上传的证件照进行图像质量分析，若存在大规模的反光(reflection)、模糊(blur)等，就需要予以拒绝)；此外，IQA也常常被用于Face Anti-Spoofing，因为有时候pr">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://raw.githubusercontent.com/lucasxlu/blog/master/source/_posts/cv-iqa/iqanet.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lucasxlu/blog/master/source/_posts/cv-iqa/iqacnn_pp.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lucasxlu/blog/master/source/_posts/cv-iqa/blinder.png">
<meta property="og:updated_time" content="2019-12-12T15:54:01.930Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[CV] Image Quality Assessment">
<meta name="twitter:description" content="IntroductionImage Quality Assessment (IQA) 是计算机视觉领域一个非常重要的研究方向，并且在许多方向也有着非常好的落地场景(例如在滴滴出行，就需要设计算法来实现对网约车司机上传的证件照进行图像质量分析，若存在大规模的反光(reflection)、模糊(blur)等，就需要予以拒绝)；此外，IQA也常常被用于Face Anti-Spoofing，因为有时候pr">
<meta name="twitter:image" content="https://raw.githubusercontent.com/lucasxlu/blog/master/source/_posts/cv-iqa/iqanet.png">
  
    <link rel="alternate" href="/atom.xml" title="LucasX" type="application/atom+xml">
  

  

  <link rel="icon" href="/blog/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/blog/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
  <link rel="stylesheet" href="/blog/css/style.css">

  <script src="/blog/js/jquery-3.1.1.min.js"></script>
  <script src="/blog/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/blog/css/bootstrap.css" >

  
    <link rel="stylesheet" href="/blog/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/blog/css/header-post.css" >
  

  
  
  
    <link rel="stylesheet" href="/blog/css/vdonate.css" ><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/blog/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/blog/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/blog/about">About</a> </li>
                
                  <li> <a class="main-nav-link" href="/blog/papers">Papers</a> </li>
                
                  <li> <a class="main-nav-link" href="/blog/projects">Projects</a> </li>
                
                  <li> <a class="main-nav-link" href="/blog/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/blog/archives">Archives</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/blog/',
        CONTENT_URL: '/blog/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/blog/js/insight.js"></script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-cv-iqa" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      [CV] Image Quality Assessment
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/blog/2019/12/07/cv-iqa/" class="article-date">
	  <time datetime="2019-12-07T14:28:11.000Z" itemprop="datePublished">2019-12-07</time>
	</a>

      
      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Image Quality Assessment (IQA) 是计算机视觉领域一个非常重要的研究方向，并且在许多方向也有着非常好的落地场景(例如在滴滴出行，就需要设计算法来实现对网约车司机上传的证件照进行图像质量分析，若存在大规模的反光(reflection)、模糊(blur)等，就需要予以拒绝)；此外，IQA也常常被用于<a href="https://lucasxlu.github.io/blog/2018/10/30/cv-antispoofing/">Face Anti-Spoofing</a>，因为有时候print/replay attack的图片/视频 和活体相比，其图像质量往往会比较差(例如颜色失真、反光、模糊、变形等)，因此也是一个非常显著的特征。</p>
<p>IQA主要分为3种：(1) 将distorted image和original image进行质量比较的，称为<em>full reference</em>。(2) 当reference image不可获取时，称为<em>no-reference</em>。(3) 当reference image只有部分可以获取时，称为<em>reduced reference</em>。</p>
<p>IQA主要的Metric是<em>MSE</em>, <em>PSNR (Peak Signal-to-Noise Ratio)</em>、<em>SROCC(Spearman Rank Order Correlation Coefficien)</em>、<em>LCC(Linear Correlation Coefficien)</em> 和 <em>SSMI (structural similarity)</em>。</p>
<ul>
<li><p>MSE measures pixel-wise error of two images</p>
</li>
<li><p>SROCC measures how well one quantity can be described as a monotonic function of another quantity.<br>$$<br>SROCC=\frac{1-6\sum_{i=1}^n d_i^2}{(n-1)n(n+1)}<br>$$</p>
</li>
<li><p>PLCC measures the linear dependence between two quantities, -1 is the standard measure for regression where +1 denotes perfect positive correlation and −1 perfect negative correlation. Values near zero de- note poor correlation. In image quality assessment PLCC is used to measure the linear correlation between the true subjective and method predicted scores.<br>$$<br>PLCC=\frac{\sum_{i=1}^n (s_i-\bar{s})(q_i-\bar{q})}{\sqrt{\sum_{i=1}^n (s_i-\bar{s})^2} \sqrt{\sum_{i=1}^n (q_i-\bar{q})^2}}<br>$$<br>where $d_i$ is the rank-order difference between the i-th image indeces in the sorted lists of the subjective ground truth and predicted scores.</p>
</li>
</ul>
<blockquote>
<p><a href="https://www.zhihu.com/people/xulu-0620/activities" target="_blank" rel="noopener">@LucasX</a>注：本文长期更新。</p>
</blockquote>
<h2 id="Convolutional-neural-networks-for-no-reference-image-quality-assessment"><a href="#Convolutional-neural-networks-for-no-reference-image-quality-assessment" class="headerlink" title="Convolutional neural networks for no-reference image quality assessment"></a>Convolutional neural networks for no-reference image quality assessment</h2><blockquote>
<p>Paper: <a href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Kang_Convolutional_Neural_Networks_2014_CVPR_paper.pdf" target="_blank" rel="noopener">Convolutional neural networks for no-reference image quality assessment</a></p>
</blockquote>
<p>这是CVPR’14的paper，应该是最早将CNN用在NR-IQA领域的paper，idea非常简单（貌似早些年的paper都是如此），作者设计了一个simple CNN来回归quality score，但与常规CNN结构不同的是，<strong>作者同时使用了MinPool与MaxPool，然后将pooled feature做拼接，在送入后续的FC layers</strong>（关于MinPooling的作用作者没说，只是能涨点）。</p>
<p>熟悉DL的同学都知道，<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">AlexNet</a>最早在NIPS’2012就已经出现了，那为啥在这段时间没人将其应用在NR-IQA呢？作者这里也给出了了原因：</p>
<blockquote>
<p>Object recognition中的CNN设计主要是为了encode local invariant part feature，而IQA则是为了capture image quality。在NR-IQA任务中，良好的特征应该能够capture NSS(Natural Scene Statistics) property。</p>
</blockquote>
<p>那么什么是NSS property？这里引用CVPR原文上的一段话吧，也很好理解：</p>
<blockquote>
<p>Typically, NSS based features characterize the distributions of certain filter responses. Traditional NSS based features are extracted in image transformation domains using, for example the wavelet transform or the DCT transform. These methods are usually very slow due to the use of computationally expensive image transformations.</p>
</blockquote>
<h3 id="CNN-for-NR-IQA"><a href="#CNN-for-NR-IQA" class="headerlink" title="CNN for NR-IQA"></a>CNN for NR-IQA</h3><p>本文的网络结构如下：<br><img src="https://raw.githubusercontent.com/lucasxlu/blog/master/source/_posts/cv-iqa/iqanet.png" alt="IQANet"></p>
<p>注：</p>
<blockquote>
<p>本文所涉及的模型，我已在<a href="https://github.com/lucasxlu/XCloud" target="_blank" rel="noopener">XCloud</a>的<a href="https://github.com/lucasxlu/XCloud/tree/master/research/iqa" target="_blank" rel="noopener">iqa</a>模块中进行了PyTorch复现，欢迎感兴趣的同学star &amp; fork。</p>
</blockquote>
<p>作者先将输入图片转成灰度，然后做contrast normalization（注：contrast norm应用在patch上，而非entire image）、sample不重叠的 $32\times 32$ patch去训练IQANet，最终每张图中$N$个patch的quality score均值即为该图的quality score，loss function为MSE。</p>
<h2 id="Multi-task-CNN-for-IQA"><a href="#Multi-task-CNN-for-IQA" class="headerlink" title="Multi-task CNN for IQA"></a>Multi-task CNN for IQA</h2><blockquote>
<p>Paper: <a href="https://ieeexplore.ieee.org/abstract/document/7351311/" target="_blank" rel="noopener">Simultaneous estimation of image quality and distortion via multi-task convolutional neural networks</a></p>
</blockquote>
<p>这篇是上述团队发表于ICIP’2015的工作，是对那篇CVPR’14的改进版本，提出了一个multi-task CNN结构，即同时regress quality score与预测distortion type，总体上也非常简单，详情可以去阅读原paper，这里记录一下几个关键点吧。</p>
<p>注：</p>
<blockquote>
<p>本文所涉及的模型，我已在<a href="https://github.com/lucasxlu/XCloud" target="_blank" rel="noopener">XCloud</a>的<a href="https://github.com/lucasxlu/XCloud/tree/master/research/iqa" target="_blank" rel="noopener">iqa</a>模块中进行了PyTorch复现，欢迎感兴趣的同学star &amp; fork。</p>
</blockquote>
<p>和<a href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Kang_Convolutional_Neural_Networks_2014_CVPR_paper.pdf" target="_blank" rel="noopener">IQANet</a>一样，回归quality score是一张图中多个patch的平均值，而图像的distortion则通过patch的majority voting得来。</p>
<p>IQACNN++网络结构如下：比<a href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Kang_Convolutional_Neural_Networks_2014_CVPR_paper.pdf" target="_blank" rel="noopener">IQANet</a>深了一些（但其实依然不算太deep），依然同时使用了MinPool和MaxPool：<br><img src="https://raw.githubusercontent.com/lucasxlu/blog/master/source/_posts/cv-iqa/iqacnn_pp.png" alt="IQACNN++"></p>
<h2 id="NIMA"><a href="#NIMA" class="headerlink" title="NIMA"></a>NIMA</h2><blockquote>
<p>Paper: <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8352823" target="_blank" rel="noopener">Nima: Neural image assessment</a></p>
</blockquote>
<p>NIMA是Google发表在TIP’18上的工作，其实整体idea也是非常简单：用图像分类的SOTA网络（例如VGG、GoogLeNet、MobileNet）来评估图像美学质量。传统的Image Aesthetic Estimation方法大多直接分类（low quality/high quality），或直接回归（mean quality score regression）。但本文旨在<strong>使模型预测值与真实值有更高的correlation</strong>，因此作者使用了<code>EMD (earth mover&#39;s distance) loss</code>，该loss被证明在<strong>对ordered class classification任务上有明显提升</strong>。</p>
<h3 id="Delve-into-NIMA"><a href="#Delve-into-NIMA" class="headerlink" title="Delve into NIMA"></a>Delve into NIMA</h3><p>人类对图像打分的分布可以表示为一种empirical probability mass function $p=[p_{s_1}, \cdots, p_{s_N}]$，其中$p_{s_1}\leq p_{s_i}\leq p_{s_N}$，其中$p_{s_i}$代表第$i$个score bucket，$N$代表bucket总数。因$\sum_{i=1}^N p_{s_i}=1$，$p_{s_i}$代表quality score落入第$i$个bucket的概率。令打分的分布为$p$，平均分为$\mu=\sum_{i=1}^N s_i\times p_{s_i}$，标准差为$\delta=(\sum_{i=1}^N (s_i-\mu)^2)^{\frac{1}{2}}$。优化目标即为找到最优probability mass function $\hat{p}$（即对$p$最准确的估计）。</p>
<h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><p>Softmax Cross-Entropy被广泛应用于多分类任务，其数学表达如下：<br>$$<br>\sum_{i=1}^N -p_{s_i}log(\hat{p}_{s_i})<br>$$<br>其中$\hat{p}_{s_i}$代表最大化正确预测类别概率的第$i$个score bucket。由上述公式可知，cross-entropy是orderless的。但是图像美学评估实际上是个ordered-class任务，而cross-entropy缺乏不同score bucket之间的inter-class relationship。那么如何处理这种场景呢？一种常见的做法是带入regression framework，本文采取了另外一种做法：<br>对于image quality ratings，类别可排序为$s_1\leq \cdots \leq s_N$，不同类别的r-norm距离可表示为$||s_i-s_j||_r$，<strong>EMD定义为移动一种分布到另一种分布的最小代价</strong>。Groundtruth probability mass function为$p$，estimated probability mass function为$\hat{p}$，则Normalized Earth Mover’s Distance可以表示为：<br>$$<br>EMD(p, \hat{p})=(\frac{1}{N}\sum_{k=1}^N |CDF_p(k)-CDF_{\hat{p}}(k)|^r)^{\frac{1}{r}}<br>$$<br>其中$CDF_p(k)$为cumulative distribution function $\sum_{i=1}^kp_{s_i}$。上式close-form solution需要distribution有相同的mass，即$\sum_{i=1}^kp_{s_i}=\sum_{i=1}^k\hat{p}_{s_i}=1$。</p>
<p>实验结果也是各种好，一句话总结吧：</p>
<blockquote>
<p>Our models effectively predict the distribution of quality ratings, rather than just the mean scores. This leads to a more accurate quality prediction with higher correlation to the ground truth ratings.</p>
</blockquote>
<h2 id="BLINDER"><a href="#BLINDER" class="headerlink" title="BLINDER"></a>BLINDER</h2><blockquote>
<p>Paper: <a href="https://www.sciencedirect.com/science/article/pii/S003132031830150X" target="_blank" rel="noopener">Blind image quality prediction by exploiting multi-level deep representations</a></p>
</blockquote>
<p>这也是一篇非常简单的paper，核心idea如下：</p>
<ol>
<li>利用ImageNet pretrained VGG提取<strong>multi-level feature</strong></li>
<li>对每个不同level的feature map做MinPool和MaxPool，然后再concatenate</li>
<li>回归多个SVR，average score ensemble</li>
</ol>
<p><img src="https://raw.githubusercontent.com/lucasxlu/blog/master/source/_posts/cv-iqa/blinder.png" alt="BLINDER"></p>
<p>方法虽然简单，但是效果貌似还很不错。作者在实验部分还发现了以下现象：</p>
<ol>
<li>relu/mpool层的效果比它前面的conv/fc层的效果差，原因可能是relu的非负性丢失了部分信息（所以这就是IQA领域喜欢结合MinPool和MaxPool一起用的原因？）</li>
<li>接近softmax层的效果correlation比较高，说明<strong>object recognition信息能够和image quality信息互补</strong></li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li>Z. Wang, A. C. Bovik, H. R. Sheikh and E. P. Simoncelli, <a href="http://www.cns.nyu.edu/pub/eero/wang03-reprint.pdf" target="_blank" rel="noopener">“Image quality assessment: From error visibility to structural similarity,”</a> IEEE Transactions on Image Processing, vol. 13, no. 4, pp. 600-612, Apr. 2004.</li>
<li>Talebi, Hossein, and Peyman Milanfar. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8352823" target="_blank" rel="noopener">“Nima: Neural image assessment.”</a> IEEE Transactions on Image Processing 27.8 (2018): 3998-4011.</li>
<li>Kang, Le, et al. <a href="http://openaccess.thecvf.com/content_cvpr_2014/papers/Kang_Convolutional_Neural_Networks_2014_CVPR_paper.pdf" target="_blank" rel="noopener">“Convolutional neural networks for no-reference image quality assessment.”</a> Proceedings of the IEEE conference on computer vision and pattern recognition. 2014.</li>
<li>Kang, Le, et al. <a href="https://ieeexplore.ieee.org/abstract/document/7351311/" target="_blank" rel="noopener">“Simultaneous estimation of image quality and distortion via multi-task convolutional neural networks.”</a> 2015 IEEE international conference on image processing (ICIP). IEEE, 2015.</li>
<li>Gao F, Yu J, Zhu S, et al. <a href="https://www.sciencedirect.com/science/article/pii/S003132031830150X" target="_blank" rel="noopener">Blind image quality prediction by exploiting multi-level deep representations</a>[J]. Pattern Recognition, 2018, 81: 432-442.</li>
<li>Bianco S, Celona L, Napoletano P, et al. <a href="https://arxiv.org/pdf/1602.05531.pdf" target="_blank" rel="noopener">On the use of deep learning for blind image quality assessment</a>[J]. Signal, Image and Video Processing, 2018, 12(2): 355-362.</li>
</ol>

      
    </div>
    <footer class="article-footer">
      
        <div id="donation_div"></div>

<script src="/blog/js/vdonate.js"></script>
<script>
var a = new Donate({
  title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: 'Donate', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: 'https://raw.githubusercontent.com/lucasxlu/blog/master/source/images/WeChatPay.png',
  alipayImage: 'https://raw.githubusercontent.com/lucasxlu/blog/master/source/images/Alipay.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>LucasX</a>
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/blog/2019/12/07/cv-iqa/" target="_blank" title="[CV] Image Quality Assessment">https://lucasxlu.github.io/blog/2019/12/07/cv-iqa/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/blog/2019/11/30/dl-data-augmentation/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">[DL] Data Augmentation</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Convolutional-neural-networks-for-no-reference-image-quality-assessment"><span class="nav-number">2.</span> <span class="nav-text">Convolutional neural networks for no-reference image quality assessment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN-for-NR-IQA"><span class="nav-number">2.1.</span> <span class="nav-text">CNN for NR-IQA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multi-task-CNN-for-IQA"><span class="nav-number">3.</span> <span class="nav-text">Multi-task CNN for IQA</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NIMA"><span class="nav-number">4.</span> <span class="nav-text">NIMA</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Delve-into-NIMA"><span class="nav-number">4.1.</span> <span class="nav-text">Delve into NIMA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Loss-Function"><span class="nav-number">4.1.1.</span> <span class="nav-text">Loss Function</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BLINDER"><span class="nav-number">5.</span> <span class="nav-text">BLINDER</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">6.</span> <span class="nav-text">Reference</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2018 - 2019 LucasX All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/blog/" class="mobile-nav-link">Home</a>
  
    <a href="/blog/about" class="mobile-nav-link">About</a>
  
    <a href="/blog/papers" class="mobile-nav-link">Papers</a>
  
    <a href="/blog/projects" class="mobile-nav-link">Projects</a>
  
    <a href="/blog/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/blog/archives" class="mobile-nav-link">Archives</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/blog/fancybox/jquery.fancybox.css">
  <script src="/blog/fancybox/jquery.fancybox.pack.js"></script>


<script src="/blog/js/scripts.js"></script>




  <script src="/blog/js/dialog.js"></script>








	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            LucasX
          </div>
          <div class="panel-body">
            Copyright © 2019 LucasX All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
</body>
</html>